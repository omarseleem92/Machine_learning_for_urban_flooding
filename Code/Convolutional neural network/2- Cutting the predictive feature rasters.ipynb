{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rasterio\n",
    "import cv2\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The below code does the following:\n",
    "     - Get the names of the predictive feature rasters\n",
    "     - Get the names of the shapefile polygons which represent the images\n",
    "     - iterate over the predictive feature rasters\n",
    "     - create a directory with the name of the predictive feature raster\n",
    "     - clip each predictive feature raster with the polygons and save it in created directories from the previous step\n",
    " \n",
    " \n",
    " Input:\n",
    " \n",
    "you need to enter the following:\n",
    "     - directory of the splitted polygons shp_path.\n",
    "     - directory of the predictive feature rasters\n",
    "     - directiry to save the cutted images\n",
    "     \n",
    "     \n",
    " Ouptut:\n",
    "     - Cutted images saved in directories with the same name of the predictive features\n",
    "\n",
    "'''\n",
    "\n",
    "# shapefile path\n",
    "shp_path=r\"D:\\USER\\seleem\\NRW\\Koeln\\Python\\Data_preperation\\Divided_polygons\\IMG_256\\Training\"\n",
    "os.chdir(shp_path)\n",
    "shp_file = glob.glob('*.shp')\n",
    "\n",
    "# predictive feature path\n",
    "predictive_rasters_path=r\"D:\\USER\\seleem\\NRW\\Koeln\\Python\\Data_preperation\\Normalized\"\n",
    "os.chdir(predictive_rasters_path)\n",
    "predictive_rasters = glob.glob('*.tif')\n",
    "\n",
    "#directory to save the images\n",
    "cutted_images_path=r\"D:\\USER\\seleem\\NRW\\Koeln\\Python\\Data_preperation\\Cutting_raster\\Github\\Training\"\n",
    "\n",
    "for raster in predictive_rasters:\n",
    "    print(str(raster))\n",
    "    os.chdir(predictive_rasters_path)\n",
    "    ds = gdal.Open(raster) # open a raster with several bands, each band  represent one predictive feature\n",
    "    gt= ds.GetGeoTransform() #get the transformation data\n",
    "    proj = ds.GetProjection() #get the projection\n",
    "\n",
    "    band = ds.GetRasterBand(1) #read the first band \n",
    "    array = band.ReadAsArray() #read the first band as an array\n",
    "    \n",
    "    #plt.figure()  #plot the raster to check that you every thing is working well\n",
    "    #plt.imshow(array)\n",
    "    \n",
    "    #create folders to save the images \n",
    "    os.mkdir(os.path.join(cutted_images_path,str(raster[11:-4])))\n",
    "     \n",
    "    \n",
    "    \n",
    "    # clip\n",
    "    \n",
    "    for shp in shp_file:\n",
    "        #print(str(file))\n",
    "        os.chdir(shp_path)\n",
    "        ds2 = ogr.Open(shp, 1)\n",
    "        layer = ds2.GetLayer()\n",
    "        shp_ds=gpd.read_file(shp)\n",
    "        #print(shp_ds['Label'][0])\n",
    "        #index+=1\n",
    "        # we will clip the raster with each polygon and save the flooded and notflooded locations in different folders\n",
    "        # we will check the label, if label =0 then this is not flooded location\n",
    "        #if shp_ds['Label'][0] == 0 : # clip and save not flooded locations\n",
    "             #Save the feature to a new shapefile\n",
    "        dsClip = gdal.Warp(os.path.join(os.path.join(cutted_images_path,str(raster[11:-4])),str(shp[:-4])+\".tif\")\n",
    "                           , ds, cutlineDSName = shp,\n",
    "                       cropToCutline = True, dstNodata = np.nan)      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainfall and Water depth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate random number list\n",
    "import random\n",
    " \n",
    "#generate a random rainfall list (rainfall depth ranges from 20 to 150 mm) with the same number of the images\n",
    "rainfall = [random.randrange(20, 160, 10) for i in range(len(shp_file))]\n",
    "#rainfall = [random.choice[20,30,40,60,70,80,90,110,120,130,150] for i in range(len(shp_file))]\n",
    "# Replace rainfall depths (50,100, and 140) with other depths. As these are going to be used to test the model\n",
    "for i,n in enumerate(rainfall):\n",
    "    if n==50:\n",
    "        rainfall[i]=random.randrange(20, 50, 10)\n",
    "    if n==100:\n",
    "        rainfall[i]=random.randrange(60, 100, 10)\n",
    "    if n==140:\n",
    "        rainfall[i]=random.randrange(110, 140, 10)\n",
    "# printing result\n",
    "print (\"Random number list is : \" +  str(rainfall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the rainfall list as a pickle\n",
    "import pickle\n",
    "\n",
    "with open('Rainfall.pkl', 'wb') as f:\n",
    "    pickle.dump(rainfall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "count=0\n",
    "for file in shp_file:\n",
    "    print(str(file)) \n",
    "    ds2 = ogr.Open(file, 1)\n",
    "    layer = ds2.GetLayer()\n",
    "    \n",
    "    # path to water depth files\n",
    "    path=r'D:\\user\\seleem\\BWB\\TELEMAC\\Hotspot0\\run\\2m'\n",
    "    path=os.path.join(path, str(rainfall[count]) + \"mm\",\"temp_result\", \"water_depth.tif\")\n",
    "\n",
    "    #print(path)\n",
    "    ds = gdal.Open(path)\n",
    "    gt= ds.GetGeoTransform()\n",
    "    proj = ds.GetProjection()\n",
    "\n",
    "    band = ds.GetRasterBand(1)\n",
    "    array = band.ReadAsArray()\n",
    "    #array=np.where(array<0, np.nan,array)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(array)\n",
    "    file_name=\"WD_\"+str(file[:-4])+\"_\"+str(rainfall[count])+\"mm.tif\"\n",
    "    #print(file_name)\n",
    "    \n",
    "    output_path=os.join.path(cutted_images_path,\"Water_depth\",file_name)\n",
    "    #print(\"Output path:\",output_path)\n",
    "       \n",
    "    dsClip = gdal.Warp(output_path, ds, cutlineDSName = file,\n",
    "                   cropToCutline = True, dstNodata = np.nan)\n",
    "    count+=1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
